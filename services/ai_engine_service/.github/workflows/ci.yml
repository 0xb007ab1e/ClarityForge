name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:

env:
  PYTHON_VERSION: '3.9'

jobs:
  test-and-coverage:
    name: Test Suite & Coverage
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Fetch full history for better coverage reporting

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-xvfb pytest-mock coverage[toml]

    - name: Create test environment file
      run: |
        cp .env.example .env
        echo "TESTING=true" >> .env
        echo "LOG_LEVEL=DEBUG" >> .env

    - name: Run test suite with coverage
      id: tests
      run: |
        # Run pytest with coverage
        python -m pytest tests/ test_service.py \
          --cov=. \
          --cov-report=xml \
          --cov-report=html \
          --cov-report=term-missing \
          --cov-fail-under=80 \
          --junitxml=pytest-results.xml \
          --verbose \
          --tb=short
      continue-on-error: true

    - name: Upload coverage reports to Codecov
      if: always()
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false

    - name: Upload test results
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: test-results
        path: |
          pytest-results.xml
          htmlcov/
          coverage.xml

    - name: Archive logs on failure
      if: failure()
      run: |
        mkdir -p logs
        echo "Build failed at $(date)" > logs/build-failure.log
        echo "Exit code: ${{ steps.tests.outcome }}" >> logs/build-failure.log
        echo "Runner: ${{ runner.os }}" >> logs/build-failure.log
        echo "Python version: ${{ env.PYTHON_VERSION }}" >> logs/build-failure.log
        echo "Commit: ${{ github.sha }}" >> logs/build-failure.log
        echo "Branch: ${{ github.ref }}" >> logs/build-failure.log
        echo "=== Test Output ===" >> logs/build-failure.log
        if [ -f pytest-results.xml ]; then
          cat pytest-results.xml >> logs/build-failure.log
        fi

    - name: Upload failure logs
      if: failure()
      uses: actions/upload-artifact@v3
      with:
        name: failure-logs
        path: logs/

    - name: Create or update issue on failure
      if: failure() && github.event_name == 'push'
      uses: actions/github-script@v7
      with:
        github-token: ${{ secrets.GITHUB_TOKEN }}
        script: |
          const { owner, repo } = context.repo;
          const sha = context.sha;
          const runId = context.runId;
          const branch = context.ref.replace('refs/heads/', '');
          
          // Search for existing build-failure issues
          const issues = await github.rest.issues.listForRepo({
            owner,
            repo,
            labels: 'build-failure',
            state: 'open'
          });
          
          const title = `ðŸš¨ Build Failure on ${branch}`;
          const body = `
          ## Build Failure Report
          
          **Branch:** \`${branch}\`
          **Commit:** \`${sha.substring(0, 7)}\`
          **Workflow Run:** [#${runId}](https://github.com/${owner}/${repo}/actions/runs/${runId})
          **Timestamp:** ${new Date().toISOString()}
          
          ### Details
          The CI/CD pipeline failed during the test and coverage step.
          
          ### Actions Taken
          - ðŸ” Test suite executed with coverage reporting
          - ðŸ“Š Coverage reports uploaded to artifacts
          - ðŸ“‹ Failure logs collected and attached
          
          ### Next Steps
          1. Review the [workflow run logs](https://github.com/${owner}/${repo}/actions/runs/${runId})
          2. Check the uploaded artifacts for detailed failure information
          3. Fix the failing tests or coverage issues
          4. Push a fix to resolve this issue
          
          ### Artifacts
          - Test results: \`pytest-results.xml\`
          - Coverage report: \`htmlcov/\`
          - Failure logs: \`logs/build-failure.log\`
          
          ---
          *This issue was automatically created by the CI/CD pipeline. It will be updated on subsequent failures and closed when the build passes.*
          `;
          
          if (issues.data.length > 0) {
            // Update existing issue
            const issueNumber = issues.data[0].number;
            await github.rest.issues.createComment({
              owner,
              repo,
              issue_number: issueNumber,
              body: `### ðŸ”„ Additional Failure\n\n${body}`
            });
            
            // Update the issue title to reflect multiple failures
            await github.rest.issues.update({
              owner,
              repo,
              issue_number: issueNumber,
              title: `${title} (Multiple Failures)`
            });
          } else {
            // Create new issue
            await github.rest.issues.create({
              owner,
              repo,
              title,
              body,
              labels: ['build-failure', 'ci/cd', 'bug']
            });
          }

    - name: Close build-failure issues on success
      if: success() && github.event_name == 'push'
      uses: actions/github-script@v7
      with:
        github-token: ${{ secrets.GITHUB_TOKEN }}
        script: |
          const { owner, repo } = context.repo;
          const sha = context.sha;
          const branch = context.ref.replace('refs/heads/', '');
          
          // Search for existing build-failure issues
          const issues = await github.rest.issues.listForRepo({
            owner,
            repo,
            labels: 'build-failure',
            state: 'open'
          });
          
          for (const issue of issues.data) {
            // Close the issue with a success comment
            await github.rest.issues.createComment({
              owner,
              repo,
              issue_number: issue.number,
              body: `### âœ… Build Fixed\n\n**Branch:** \`${branch}\`\n**Commit:** \`${sha.substring(0, 7)}\`\n\nThe build is now passing. This issue is being automatically closed.`
            });
            
            await github.rest.issues.update({
              owner,
              repo,
              issue_number: issue.number,
              state: 'closed'
            });
          }

    - name: Update build status badge
      if: always()
      run: |
        # Create a simple status badge update (this would typically integrate with shields.io or similar)
        STATUS="${{ steps.tests.outcome }}"
        if [ "$STATUS" = "success" ]; then
          echo "Build Status: âœ… Passing" > build-status.txt
          echo "BADGE_COLOR=brightgreen" >> $GITHUB_ENV
          echo "BADGE_MESSAGE=passing" >> $GITHUB_ENV
        else
          echo "Build Status: âŒ Failing" > build-status.txt
          echo "BADGE_COLOR=red" >> $GITHUB_ENV
          echo "BADGE_MESSAGE=failing" >> $GITHUB_ENV
        fi
        
        # Get coverage percentage for badge
        if [ -f coverage.xml ]; then
          COVERAGE=$(python -c "
        import xml.etree.ElementTree as ET
        try:
            tree = ET.parse('coverage.xml')
            root = tree.getroot()
            coverage = root.attrib.get('line-rate', '0')
            print(f'{float(coverage)*100:.0f}')
        except:
            print('0')
        ")
          echo "COVERAGE_PERCENT=$COVERAGE" >> $GITHUB_ENV
        else
          echo "COVERAGE_PERCENT=0" >> $GITHUB_ENV
        fi

    - name: Post build status to PR
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        github-token: ${{ secrets.GITHUB_TOKEN }}
        script: |
          const { owner, repo } = context.repo;
          const prNumber = context.payload.pull_request.number;
          const status = '${{ steps.tests.outcome }}';
          const coverage = '${{ env.COVERAGE_PERCENT }}';
          
          const statusEmoji = status === 'success' ? 'âœ…' : 'âŒ';
          const statusText = status === 'success' ? 'PASSED' : 'FAILED';
          
          const comment = `
          ## ðŸ¤– CI/CD Build Report
          
          **Status:** ${statusEmoji} **${statusText}**
          **Coverage:** ${coverage}%
          **Commit:** \`${{ github.event.pull_request.head.sha.substring(0, 7) }}\`
          
          ${status === 'success' ? 
            'ðŸŽ‰ All tests are passing and coverage requirements are met!' : 
            'âš ï¸ Tests failed or coverage is below the required threshold. Please check the logs and fix the issues.'
          }
          
          [View detailed results](https://github.com/${owner}/${repo}/actions/runs/${{ github.run_id }})
          `;
          
          await github.rest.issues.createComment({
            owner,
            repo,
            issue_number: prNumber,
            body: comment
          });

  # Optional: Slack/Webhook Notifications
  notify:
    name: Notifications
    runs-on: ubuntu-latest
    needs: test-and-coverage
    if: always() && (github.event_name == 'push' && github.ref == 'refs/heads/main')
    
    steps:
    - name: Send Slack notification
      if: env.SLACK_WEBHOOK_URL != ''
      uses: 8398a7/action-slack@v3
      with:
        status: ${{ needs.test-and-coverage.result }}
        channel: '#ci-cd'
        webhook_url: ${{ secrets.SLACK_WEBHOOK_URL }}
        fields: repo,message,commit,author,action,eventName,ref,workflow
        custom_payload: |
          {
            attachments: [{
              color: '${{ needs.test-and-coverage.result }}' === 'success' ? 'good' : 'danger',
              blocks: [
                {
                  type: 'section',
                  text: {
                    type: 'mrkdwn',
                    text: `*AI Engine Service CI/CD*\n${{ needs.test-and-coverage.result == 'success' && 'âœ… Build passed' || 'âŒ Build failed' }}`
                  }
                },
                {
                  type: 'context',
                  elements: [
                    {
                      type: 'mrkdwn',
                      text: `Branch: \`${{ github.ref_name }}\` | Commit: \`${{ github.sha }}\` | Author: ${{ github.actor }}`
                    }
                  ]
                }
              ]
            }]
          }
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

    - name: Send webhook notification
      if: env.WEBHOOK_URL != ''
      run: |
        curl -X POST "${{ secrets.WEBHOOK_URL }}" \
          -H "Content-Type: application/json" \
          -d '{
            "service": "ai-engine-service",
            "status": "${{ needs.test-and-coverage.result }}",
            "branch": "${{ github.ref_name }}",
            "commit": "${{ github.sha }}",
            "author": "${{ github.actor }}",
            "timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'",
            "workflow_url": "https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          }'
      env:
        WEBHOOK_URL: ${{ secrets.WEBHOOK_URL }}

  # Build status badge generation
  badge:
    name: Generate Status Badge
    runs-on: ubuntu-latest
    needs: test-and-coverage
    if: always() && github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}

    - name: Generate and commit badge
      run: |
        # Create badges directory if it doesn't exist
        mkdir -p .badges
        
        # Generate build status badge
        STATUS="${{ needs.test-and-coverage.result }}"
        if [ "$STATUS" = "success" ]; then
          COLOR="brightgreen"
          MESSAGE="passing"
        else
          COLOR="red"
          MESSAGE="failing"
        fi
        
        # Generate badge URLs (using shields.io)
        BUILD_BADGE_URL="https://img.shields.io/badge/build-${MESSAGE}-${COLOR}"
        COVERAGE_BADGE_URL="https://img.shields.io/badge/coverage-${{ env.COVERAGE_PERCENT }}%25-blue"
        
        # Create badge markdown
        cat > .badges/README.md << EOF
        # AI Engine Service Badges
        
        ![Build Status](${BUILD_BADGE_URL})
        ![Coverage](${COVERAGE_BADGE_URL})
        
        Last updated: $(date -u)
        EOF
        
        # Commit badge updates if running on main branch
        if [ -n "$(git status --porcelain)" ]; then
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add .badges/
          git commit -m "Update build status badges [skip ci]" || exit 0
          git push
        fi
